# 🖼️ Image Caption Generator using Hugging Face & Streamlit

This project is a simple web application that automatically generates descriptive captions for uploaded images. It uses a pre-trained VisionEncoderDecoder model (`ydshieh/vit-gpt2-coco-en`) from the Hugging Face Transformers library and is built using Streamlit.  It allows users to interactively upload images and get meaningful descriptions generated by state-of-the-art vision-language models. 


---

## 🚀 Demo

Upload an image, and the app will return a natural language description of the image content.

---

## 📦 Features

- Upload `.jpg`, `.jpeg`, or `.png` images  
- Generates a descriptive caption using a powerful image-to-text transformer model  
- Clean and interactive UI powered by Streamlit

---

## 🧠 Model

The model used is [`ydshieh/vit-gpt2-coco-en`](https://huggingface.co/ydshieh/vit-gpt2-coco-en), a Vision Transformer (ViT) encoder with GPT2 decoder fine-tuned on the COCO dataset for image captioning.

---

## 🛠️ Installation

### 1. Clone the repository

```bash
git clone https://github.com/your-username/image-caption-generator.git
cd image-caption-generator
```

### 2. Install dependencies

Make sure you have Python ≥ 3.8 installed. Then run:

```bash
pip install -r requirements.txt
```

--- 

## ▶️ Usage

Run the Streamlit app locally:

```bash
streamlit run app.py
```
Then, open your browser and go to: (http://localhost:8501)

---

## 📂 File Structure

```bash

📁 image-caption-generator/
├── app.py               # Main Streamlit app
├── requirements.txt     # Required Python libraries
└── README.md            # Project documentation
```

---

## 🙌 Acknowledgments

1. Hugging Face Transformers
2. Streamlit
3. Pretrained model: ydshieh/vit-gpt2-coco-en

---
