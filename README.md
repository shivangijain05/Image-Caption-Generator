# ğŸ–¼ï¸ Image Caption Generator using Hugging Face & Streamlit

This project is a simple web application that automatically generates descriptive captions for uploaded images. It uses a pre-trained VisionEncoderDecoder model (`ydshieh/vit-gpt2-coco-en`) from the Hugging Face Transformers library and is built using Streamlit.  It allows users to interactively upload images and get meaningful descriptions generated by state-of-the-art vision-language models. 


---

## ğŸš€ Demo

Upload an image, and the app will return a natural language description of the image content.

---

## ğŸ“¦ Features

- Upload `.jpg`, `.jpeg`, or `.png` images  
- Generates a descriptive caption using a powerful image-to-text transformer model  
- Clean and interactive UI powered by Streamlit

---

## ğŸ§  Model

The model used is [`ydshieh/vit-gpt2-coco-en`](https://huggingface.co/ydshieh/vit-gpt2-coco-en), a Vision Transformer (ViT) encoder with GPT2 decoder fine-tuned on the COCO dataset for image captioning.

---

## ğŸ› ï¸ Installation

### 1. Clone the repository

```bash
git clone https://github.com/your-username/image-caption-generator.git
cd image-caption-generator
```

### 2. Install dependencies

Make sure you have Python â‰¥ 3.8 installed. Then run:

```bash
pip install -r requirements.txt
```

--- 

## â–¶ï¸ Usage

Run the Streamlit app locally:

```bash
streamlit run app.py
```
Then, open your browser and go to: (http://localhost:8501)

---

## ğŸ“‚ File Structure

```bash

ğŸ“ image-caption-generator/
â”œâ”€â”€ app.py               # Main Streamlit app
â”œâ”€â”€ requirements.txt     # Required Python libraries
â””â”€â”€ README.md            # Project documentation
```

---

## ğŸ™Œ Acknowledgments

1. Hugging Face Transformers
2. Streamlit
3. Pretrained model: ydshieh/vit-gpt2-coco-en

---
